{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc95f47-1dbe-404a-a348-9a4930101ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.windows import from_bounds\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from patchify import patchify\n",
    "import torch\n",
    "from torch.functional import F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from shapely.geometry import box\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import random\n",
    "\n",
    "from pytorch_segmentation.data.rwanda_dataset import RwandaDataset\n",
    "from pytorch_segmentation.data.inmemory_dataset import InMemorySatDataset\n",
    "from pytorch_segmentation.train_net import train\n",
    "from pytorch_segmentation.models import UNet\n",
    "import pytorch_segmentation.augmentation.transforms as seg_transforms\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1aabc9-3b5d-4cfc-8398-eb910d8d2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = \"/home/jovyan/work/satellite_data/tmp/2018.vrt\"\n",
    "label_path = \"data/label_masks/train\"\n",
    "test_label_path = \"data/label_masks/test\"\n",
    "tensorboard_path = \"/home/jovyan/work/runs\"\n",
    "\n",
    "test_patch_size = [256,256,3]\n",
    "overlap = 192\n",
    "padding = False#True\n",
    "\n",
    "\n",
    "#batch_size = 200\n",
    "#batch_size = 50\n",
    "batch_size = 150\n",
    "\n",
    "nworkers = 4\n",
    "pin_memory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66789f5d-0d0e-4c3f-9515-fde42c8e9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "save_dir = \"saved_models\"\n",
    "\n",
    "\n",
    "test_transform = None\n",
    "#test_transform = seg_transforms.Normalize(mean=[0.5492, 0.5190, 0.4393],\n",
    "#                                          std=[0.1381, 0.1320, 0.1349])\n",
    "\n",
    "model_name = \"unet_05_05_2022_113034\"\n",
    "model_path = save_dir+\"/\"+model_name+\".pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af185645-8fc2-4381-adea-51fd10faba18",
   "metadata": {},
   "source": [
    "# 1.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2af811-a6f2-4818-826d-f708187d8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = InMemorySatDataset(data_file_path=data_path,mask_path=label_path,\n",
    "                             overlap=overlap,patch_size=test_patch_size,padding=padding,transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440c53f-067d-48c1-96ec-59479d1e249e",
   "metadata": {},
   "source": [
    "# 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ae2866-cbd7-47f4-9ccd-a85c490cda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change here to adapt to your data\n",
    "# n_channels=3 for RGB images \n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "\n",
    "\n",
    "net = UNet(n_channels=3, n_classes=2, bilinear=False)\n",
    "#net= DataParallel(net)\n",
    "\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "net = net.to(device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9f0ec9-0f1b-44c4-8cb6-7426091313fa",
   "metadata": {},
   "source": [
    "## 3 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b804bc86-5a78-4815-979b-956806bd7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_dataset,batch_size=batch_size,num_workers=nworkers,pin_memory=pin_memory,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4d48f0-e8cb-45a5-824a-f9a88af0fd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "output = []\n",
    "y_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i,batch in enumerate(test_dl):\n",
    "        x = batch[\"x\"].to(device)\n",
    "        out = net(x)#[\"out\"]\n",
    "        #out = F.softmax(out,dim=1)\n",
    "        out = torch.argmax(out,dim=1)\n",
    "        out = out.cpu().numpy()\n",
    "        output.append(out)\n",
    "        y_test.extend(batch[\"y\"].numpy())\n",
    "    y_pred = torch.as_tensor(np.vstack(output))\n",
    "    y_test = torch.as_tensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6fb1c6-054b-4805-b601-cc20c2b0a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(y_pred,target,absent_score=1.0):\n",
    "    numerator = torch.sum(y_pred * target,dim=1)  # TP\n",
    "    denominator = torch.sum(y_pred + target,dim=1) - numerator  # 2TP + FP + FN - TP\n",
    "    iou = (numerator) / (denominator)\n",
    "    iou[denominator == 0] = absent_score\n",
    "    return iou.mean()\n",
    "\n",
    "def dice_coeff(y_pred, target,absent_score=1.0):\n",
    "    # F1 = TP / (TP + 0.5 (FP + FN)) = 2TP / (2TP + FP + FN)\n",
    "    numerator = 2 * torch.sum(y_pred * target,dim=1)  # 2TP\n",
    "    denominator = torch.sum(y_pred + target,dim=1)  # 2TP + FP + FN\n",
    "    dice = (numerator) / (denominator)\n",
    "    dice[denominator == 0] = absent_score\n",
    "    return dice.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f35aeb0c-1ca7-43f9-9364-2b777cb044f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_05_05_2022_113034\n",
      "IoU:  0.7121449112892151\n",
      "Dice score:  0.7348865866661072\n",
      "Accuracy:  0.9825443625450134\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc},**test_dataset.get_config()}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f19a2-8d70-4b30-b708-5d4ff087a6dd",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d17cb3-82e7-4889-8e18-9dce776d2aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_09_05_2022_110252\n",
      "IoU:  0.835816502571106\n",
      "Dice score:  0.8585439324378967\n",
      "Accuracy:  0.9832549691200256\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc},**test_dataset.get_config()}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9620a28b-d4e1-4d96-ae90-9778cf87a2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_05_05_2022_113034\n",
      "IoU:  0.7121449112892151\n",
      "Dice score:  0.7348865866661072\n",
      "Accuracy:  0.9825443625450134\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc},**test_dataset.get_config()}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18227a99-0b78-4d39-a2e8-5dfd1d8b0634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_06_05_2022_070627\n",
      "IoU:  0.8286783695220947\n",
      "Dice score:  0.851495623588562\n",
      "Accuracy:  0.9829235672950745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc},**test_dataset.get_config()}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34bf4311-3c6b-4833-b09e-5c1f5e850471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_06_05_2022_071606\n",
      "IoU:  0.8318414688110352\n",
      "Dice score:  0.8548348546028137\n",
      "Accuracy:  0.983232319355011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc},**test_dataset.get_config()}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a562e22d-361b-4276-8c9d-88339f04b7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_06_05_2022_070624\n",
      "IoU:  0.8266518115997314\n",
      "Dice score:  0.849705159664154\n",
      "Accuracy:  0.9835194945335388\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc},**test_dataset.get_config()}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3895bdba-276b-4674-ab38-491975984a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_06_05_2022_072927\n",
      "IoU:  0.8136389255523682\n",
      "Dice score:  0.8368015289306641\n",
      "Accuracy:  0.9829322099685669\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc},**test_dataset.get_config()}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
