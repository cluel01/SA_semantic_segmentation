{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc95f47-1dbe-404a-a348-9a4930101ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.windows import from_bounds\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from patchify import patchify\n",
    "import torch\n",
    "from torch.functional import F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from shapely.geometry import box\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import random\n",
    "\n",
    "from pytorch_segmentation.data.rwanda_dataset import RwandaDataset\n",
    "from pytorch_segmentation.data.inmemory_dataset import InMemorySatDataset\n",
    "from pytorch_segmentation.train_net import train\n",
    "from pytorch_segmentation.models import UNet\n",
    "import pytorch_segmentation.augmentation.transforms as seg_transforms\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1aabc9-3b5d-4cfc-8398-eb910d8d2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"unet_11_07_2022_070457\" \n",
    "data_parallel = True\n",
    "\n",
    "save_dir = \"saved_models\"\n",
    "\n",
    "#SA data\n",
    "data_path = \"/home/jovyan/work/satellite_data/tmp/2018.vrt\"\n",
    "label_path_sa_test = \"data/datasets/V5/test/SA\"\n",
    "\n",
    "#Rwanda data\n",
    "shape_path_rw = \"data/datasets/V1/rwanda_tree_shapes/training_data_polygons_model_29_v2.shp\"\n",
    "test_data_path_rw = \"data/datasets/V5/test/rwanda\"\n",
    "\n",
    "test_patch_size = [256,256,3]\n",
    "overlap_test = 128\n",
    "\n",
    "batch_size = 50\n",
    "nworkers = 10\n",
    "pin_memory = True\n",
    "\n",
    "padding = False#True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66789f5d-0d0e-4c3f-9515-fde42c8e9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "if str(device) == \"cpu\":\n",
    "    pin_memory = False\n",
    "\n",
    "test_transform = None\n",
    "\n",
    "test_transform = seg_transforms.Compose([\n",
    "    #seg_transforms.UnmaskEdges([225,225]),\n",
    "     #seg_transforms.CLAHE_Norm(),\n",
    "    #seg_transforms.Add_VDVI()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af185645-8fc2-4381-adea-51fd10faba18",
   "metadata": {},
   "source": [
    "# 1.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2af811-a6f2-4818-826d-f708187d8647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Test:  724\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataset_sa = InMemorySatDataset(data_file_path=data_path,mask_path=label_path_sa_test,\n",
    "                             overlap=overlap_test,patch_size=test_patch_size,padding=padding,transform=test_transform)\n",
    "\n",
    "print(\"Len Test: \",len(test_dataset_sa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d4254c-229a-4944-8075-31b34f6770eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:12<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Test:  1688\n"
     ]
    }
   ],
   "source": [
    "test_dataset_rw = RwandaDataset(dataset_path=None,data_file_path=test_data_path_rw,\n",
    "                   shape_path=shape_path_rw, overlap=overlap_test,patch_size=test_patch_size,padding=padding,transform=test_transform)\n",
    "\n",
    "print(\"Len Test: \",len(test_dataset_rw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "780c0d43-0885-470f-b648-56a5e308ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torch.utils.data.ConcatDataset([test_dataset_rw, test_dataset_sa])\n",
    "test_dl = DataLoader(test_dataset,batch_size=batch_size,num_workers=nworkers,\n",
    "                     shuffle=False,pin_memory=pin_memory,drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440c53f-067d-48c1-96ec-59479d1e249e",
   "metadata": {},
   "source": [
    "# 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f9052ff-53b5-4395-b8fb-5de9d16daa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = save_dir + \"/\" + model_name +  \".pth\"\n",
    "state_dict = torch.load(model_path,map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68038413-e2eb-4db4-9cf2-9be1dcd6d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if data_parallel:\n",
    "    # create new OrderedDict that does not contain `module.`\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    model_path = save_dir + \"/\" + model_name +  \"_new.pth\"\n",
    "    torch.save(new_state_dict,model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45820f-e211-4304-9886-d0b344ef8ed7",
   "metadata": {},
   "source": [
    "## 2.1 Advanced Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae2866-cbd7-47f4-9ccd-a85c490cda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change here to adapt to your data\n",
    "# n_channels=3 for RGB images \n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "\n",
    "net = UNet(n_channels=3, n_classes=2, bilinear=False)\n",
    "#net= DataParallel(net)\n",
    "\n",
    "if data_parallel:\n",
    "    net.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    net.load_state_dict(state_dict)\n",
    "#net.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n",
    "\n",
    "net = net.to(device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcbe6a2-e6da-4604-9f48-44a8a2d44cc9",
   "metadata": {},
   "source": [
    "## 2.2 Pretrained Unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f7cd6-6f5a-43e6-8229-baed5cd89b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "net = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2\n",
    ")\n",
    "\n",
    "\n",
    "if data_parallel:\n",
    "    net.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "net = net.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9f0ec9-0f1b-44c4-8cb6-7426091313fa",
   "metadata": {},
   "source": [
    "## 3 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec4d48f0-e8cb-45a5-824a-f9a88af0fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "output = []\n",
    "y_test = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for i,batch in enumerate(test_dl):\n",
    "        x = batch[\"x\"].to(device)\n",
    "        out = net(x)#[\"out\"]\n",
    "        #out = F.softmax(out,dim=1)\n",
    "        out = torch.argmax(out,dim=1)\n",
    "        out = out.cpu().numpy()\n",
    "        output.append(out)\n",
    "        y_test.extend(batch[\"y\"].numpy())\n",
    "    y_pred = torch.as_tensor(np.vstack(output))\n",
    "    y_test = torch.as_tensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c6fb1c6-054b-4805-b601-cc20c2b0a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(y_pred,target,absent_score=1.0):\n",
    "    numerator = torch.sum(y_pred * target,dim=1)  # TP\n",
    "    denominator = torch.sum(y_pred + target,dim=1) - numerator  # 2TP + FP + FN - TP\n",
    "    iou = (numerator) / (denominator)\n",
    "    iou[denominator == 0] = absent_score\n",
    "    return iou.mean()\n",
    "\n",
    "def dice_coeff(y_pred, target,absent_score=1.0):\n",
    "    # F1 = TP / (TP + 0.5 (FP + FN)) = 2TP / (2TP + FP + FN)\n",
    "    numerator = 2 * torch.sum(y_pred * target,dim=1)  # 2TP\n",
    "    denominator = torch.sum(y_pred + target,dim=1)  # 2TP + FP + FN\n",
    "    dice = (numerator) / (denominator)\n",
    "    dice[denominator == 0] = absent_score\n",
    "    return dice.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f35aeb0c-1ca7-43f9-9364-2b777cb044f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_29_06_2022_063800\n",
      "IoU:  0.67069411277771\n",
      "Dice score:  0.756680428981781\n",
      "Accuracy:  0.9545283913612366\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfdb8a-1f3a-48e5-b3d9-76c8280c5e99",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3df76-99c0-4a42-9979-0dd711b945a9",
   "metadata": {},
   "source": [
    "## V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "299a0cad-3919-407d-b13e-2a68b04dbe21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_08_07_2022_120733\n",
      "IoU:  0.6299372911453247\n",
      "Dice score:  0.7153642177581787\n",
      "Accuracy:  0.9519509673118591\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d848ee7d-033f-4fb1-953f-c76388ace8fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_09_07_2022_091213\n",
      "IoU:  0.6079014539718628\n",
      "Dice score:  0.6967523694038391\n",
      "Accuracy:  0.9387077689170837\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c6bce3-ce07-4c6a-8348-2c8a0615b26d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_29_06_2022_063800\n",
      "IoU:  0.67069411277771\n",
      "Dice score:  0.756680428981781\n",
      "Accuracy:  0.9545283913612366\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8f720-010a-4c36-b38a-11100ce338c8",
   "metadata": {},
   "source": [
    "## V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5522f95e-a554-4f74-a668-20305ba9de09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_29_06_2022_063800\n",
      "IoU:  0.6824602484703064\n",
      "Dice score:  0.7717554569244385\n",
      "Accuracy:  0.9403427243232727\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "025f632d-2967-478f-84c0-43455927d361",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_05_07_2022_092338\n",
      "IoU:  0.6342746615409851\n",
      "Dice score:  0.7236443758010864\n",
      "Accuracy:  0.9284062385559082\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51835de2-0cb5-4678-819a-b204c0f10dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_04_07_2022_094003\n",
      "IoU:  0.6387783885002136\n",
      "Dice score:  0.729936420917511\n",
      "Accuracy:  0.927946150302887\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6440c98b-36a4-47cc-830c-74937fda7414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_pretrained_04_07_2022_141315\n",
      "IoU:  0.6783024668693542\n",
      "Dice score:  0.7673388719558716\n",
      "Accuracy:  0.938949704170227\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b39da6-9c21-4d7e-8c41-3d7d74a0c8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_pretrained_04_07_2022_141315\n",
      "IoU:  0.6783024668693542\n",
      "Dice score:  0.7673388719558716\n",
      "Accuracy:  0.938949704170227\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97ca41bf-df25-49c1-a029-d64b045ed148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_24_06_2022_082330\n",
      "IoU:  0.6615725159645081\n",
      "Dice score:  0.7537617683410645\n",
      "Accuracy:  0.9354711771011353\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe93810d-e1a8-4057-b022-9c4b88e2d0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_28_06_2022_060037\n",
      "IoU:  0.6614326238632202\n",
      "Dice score:  0.7512581944465637\n",
      "Accuracy:  0.9385855793952942\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6bbecae-7656-45de-8290-3a37bb8454e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_27_06_2022_091925\n",
      "IoU:  0.6486105918884277\n",
      "Dice score:  0.7404710054397583\n",
      "Accuracy:  0.9343949556350708\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c717e60-b55d-498b-bc84-39dfd330983a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_25_06_2022_155958\n",
      "IoU:  0.6480911374092102\n",
      "Dice score:  0.7394369840621948\n",
      "Accuracy:  0.9371793866157532\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a6c0de-d589-4982-ac72-23c67d42764c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_dropout_24_06_2022_112935\n",
      "IoU:  0.5971380472183228\n",
      "Dice score:  0.6796640157699585\n",
      "Accuracy:  0.9256259799003601\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbd65b5-4040-43f7-98eb-c8ebfc11c0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_23_06_2022_155611\n",
      "IoU:  0.7964387536048889\n",
      "Dice score:  0.863918662071228\n",
      "Accuracy:  0.9613916277885437\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "026f9340-c46e-4eb2-a908-b318a33c71ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_16_06_2022_190207\n",
      "IoU:  0.7564991116523743\n",
      "Dice score:  0.8263688087463379\n",
      "Accuracy:  0.9605708718299866\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43384d78-6b26-4bdb-b136-0acede44c693",
   "metadata": {},
   "source": [
    "# V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d75666e7-ba6d-4055-aa66-d51bb457dc03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_23_06_2022_155611\n",
      "IoU:  0.6391757130622864\n",
      "Dice score:  0.7047642469406128\n",
      "Accuracy:  0.9544192552566528\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffcb4d46-c58b-4ff8-a5e3-0fb816c517e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_16_06_2022_190207\n",
      "IoU:  0.6387537717819214\n",
      "Dice score:  0.6955344676971436\n",
      "Accuracy:  0.9621475338935852\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95dd0795-cff0-4f71-a470-168d7b1da27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_05_05_2022_113034\n",
      "IoU:  0.5952672958374023\n",
      "Dice score:  0.6595103144645691\n",
      "Accuracy:  0.9641584753990173\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e881342-6127-4dce-bb4a-69e2667817d2",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83c5f8c1-4c1b-4879-8805-07cfcf83f3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_20_06_2022_191546\n",
      "IoU:  0.5250652432441711\n",
      "Dice score:  0.6007120013237\n",
      "Accuracy:  0.9516292810440063\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032426c1-eca7-4cad-9ad8-e9a3570585bf",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be84026-340f-4e4f-86f5-15f3bc3888dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_16_06_2022_190207\n",
      "IoU:  0.566116213798523\n",
      "Dice score:  0.658390462398529\n",
      "Accuracy:  0.9544999003410339\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0d8de03-01e6-45f8-b311-80ca28c3aa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_20_06_2022_124519\n",
      "IoU:  0.5042276978492737\n",
      "Dice score:  0.5929812788963318\n",
      "Accuracy:  0.948485791683197\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3c164bb-6246-4fa8-a687-7309b85c7041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_20_06_2022_124129\n",
      "IoU:  0.5082292556762695\n",
      "Dice score:  0.598351776599884\n",
      "Accuracy:  0.9469634890556335\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68d361ee-67ad-4a97-a6a5-f8a487cfbfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_19_06_2022_174825\n",
      "IoU:  0.4608975946903229\n",
      "Dice score:  0.5462993383407593\n",
      "Accuracy:  0.9406550526618958\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fc83876-34c1-41eb-9c64-3cd4a7a3cbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_19_06_2022_101139\n",
      "IoU:  0.5205713510513306\n",
      "Dice score:  0.6123562455177307\n",
      "Accuracy:  0.946079671382904\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a7891fe-1e1a-42f1-a89a-578747c2ef68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_19_06_2022_101139\n",
      "IoU:  0.537010669708252\n",
      "Dice score:  0.6275419592857361\n",
      "Accuracy:  0.945489764213562\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91c8edd9-465e-4340-a97f-41e1aa40b426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_19_06_2022_095748\n",
      "IoU:  0.49590927362442017\n",
      "Dice score:  0.5872480869293213\n",
      "Accuracy:  0.9463361501693726\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea18f721-10a3-4bd0-b882-3871cabadfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_17_06_2022_205231\n",
      "IoU:  0.48862332105636597\n",
      "Dice score:  0.578204333782196\n",
      "Accuracy:  0.9475828409194946\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7136dc-12a6-4867-85ff-16532b69941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_17_06_2022_124956\n",
      "IoU:  0.48286178708076477\n",
      "Dice score:  0.5737370848655701\n",
      "Accuracy:  0.9456601142883301\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c895f87-1050-48a6-b70c-02f8ce4092fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_17_06_2022_082105\n",
      "IoU:  0.47791990637779236\n",
      "Dice score:  0.5681964159011841\n",
      "Accuracy:  0.9438368678092957\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c73ac669-e178-4131-bc30-7f73699e5212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_17_06_2022_082054\n",
      "IoU:  0.4992392957210541\n",
      "Dice score:  0.5876631140708923\n",
      "Accuracy:  0.9477913975715637\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24c8ce7-b151-4c4a-9b71-6739a925e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_05_05_2022_113034\n",
      "IoU:  0.5547717213630676\n",
      "Dice score:  0.645209789276123\n",
      "Accuracy:  0.9556285738945007\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d76037b-c28b-4b5b-b60f-5bcdb6ae5487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_15_06_2022_175944\n",
      "IoU:  0.45879825949668884\n",
      "Dice score:  0.5451763868331909\n",
      "Accuracy:  0.9410678744316101\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0662e60c-f83f-4c37-a91a-5b6e6e0d9c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_14_06_2022_143718\n",
      "IoU:  0.5262002944946289\n",
      "Dice score:  0.6148598194122314\n",
      "Accuracy:  0.9428917765617371\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76969027-4ae6-4d35-be52-e07c638f812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_16_06_2022_083705\n",
      "IoU:  0.5006430149078369\n",
      "Dice score:  0.5897845029830933\n",
      "Accuracy:  0.9438526034355164\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a5e07-80a6-40f5-aefe-774a93b8ef8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd807b-be2c-4ffa-9ce2-cc97626311a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08048e-479f-44eb-8e5a-ae7b2b735933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d45e89c-b463-42db-8523-690b565c2a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_09_06_2022_091550\n",
      "IoU:  0.8330698013305664\n",
      "Dice score:  0.8749065399169922\n",
      "Accuracy:  0.9755495190620422\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee6a3a9-b54c-492e-afcd-29bd562ff57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_08_06_2022_123439\n",
      "IoU:  0.817255973815918\n",
      "Dice score:  0.8576894998550415\n",
      "Accuracy:  0.9728814959526062\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c34fd439-9ae3-4d46-87e5-110c715e1aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_07_06_2022_140803\n",
      "IoU:  0.8471149802207947\n",
      "Dice score:  0.8872880935668945\n",
      "Accuracy:  0.9784597754478455\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a88efb90-096e-4302-86b3-268f40f2ddf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  unet_06_06_2022_131709\n",
      "IoU:  0.8556468486785889\n",
      "Dice score:  0.8879135847091675\n",
      "Accuracy:  0.9806501865386963\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "y_pred = y_pred.reshape(y_pred.size(0),-1)\n",
    "y_test = y_test.reshape(y_test.size(0),-1)\n",
    "\n",
    "print(\"Model: \",model_name)\n",
    "iou = iou_score(y_pred,y_test).item()\n",
    "print(f\"IoU: \",iou)\n",
    "dice = dice_coeff(y_pred,y_test).item()\n",
    "print(\"Dice score: \",dice)\n",
    "acc = (torch.sum(y_pred == y_test)/torch.numel(y_pred)).item()\n",
    "print(\"Accuracy: \",acc)\n",
    "# f1 = f1_score(y_pred.reshape(-1).numpy(),y_test.reshape(-1).numpy())\n",
    "# print(\"F1 score: \",f1)\n",
    "#accuracy = accuracy(imgs,test_dataset.y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Pixel accuracy: \",dice_score)\n",
    "df = pd.DataFrame([{**{\"model_name\":model_path,\"IoU\":iou,\"dice_score\":dice,\n",
    "                       \"Accuracy\":acc}}])\n",
    "df.to_csv(model_path+\"_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfcbd29-1651-40ad-84c7-5589e31cc69a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bee7f49-753a-46fa-8b5c-bfff810f4b0b",
   "metadata": {},
   "source": [
    "## 2.3 Unet  Dropout\n",
    "https://github.com/zijundeng/pytorch-semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eba130ff-b9a1-4c64-8eb8-11a67975d37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/notebooks/satellite_data/pytorch_segmentation/models/unet_dropout.py:84: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(module.weight)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_segmentation.models.unet_dropout import UNet\n",
    "\n",
    "\n",
    "# Change here to adapt to your data\n",
    "net = UNet(num_classes=2)\n",
    "\n",
    "if data_parallel:\n",
    "    net.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "net = net.to(device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
