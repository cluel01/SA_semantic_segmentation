{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b823063-72c5-4611-9146-0b721d60bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.windows import from_bounds\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from patchify import patchify\n",
    "import torch\n",
    "from torch.functional import F\n",
    "from torch import nn\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "from shapely.geometry import box\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import random\n",
    "import torchvision.models as models\n",
    "from pytorch_segmentation.data.train_dataset import TrainDataset\n",
    "from pytorch_segmentation.data.test_dataset import TestSatDataset\n",
    "from pytorch_segmentation.models import UNet\n",
    "import pytorch_segmentation.augmentation.transforms as seg_transforms\n",
    "\n",
    "from pytorch_segmentation.validate import validate\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1a0e39-b8c8-4bec-b5a3-73b37627339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"save_dir\" : \"saved_models\",\n",
    "    \"model_name\" : \"unet_01_12_2022_085945\",\n",
    "    \"data_parallel\": True,\n",
    "    \n",
    "    \"mode\": \"worst\",\n",
    "    \"nimgs\": 2000,\n",
    "    \n",
    "    #SA high resoluted data\n",
    "    \"shape_path_sa_high\": \"data/datasets/V24/data_pool/SA_tree_shapes/labels.geojson\",\n",
    "    \"train_data_path_sa_high\": \"data/datasets/V24/train/SA_high\",\n",
    "    \"val_data_path_sa_high\": \"data/datasets/V24/val/SA_high\",\n",
    "    \"test_data_path_sa_high\": \"data/datasets/V24/test/SA_high\",\n",
    "\n",
    "    #SA low data\n",
    "    \"shape_path_sa_low\": \"data/datasets/V24/data_pool/SA_tree_shapes/labels.geojson\",\n",
    "    \"train_data_path_sa_low\": \"data/datasets/V24/train/SA_low\",\n",
    "    \"val_data_path_sa_low\": \"data/datasets/V24/val/SA_low\",\n",
    "    \"test_data_path_sa_low\": \"data/datasets/V24/test/SA_low\",\n",
    "    \n",
    "    \n",
    "    #Rwanda data 2008\n",
    "    \"shape_path_rw_2008\": \"data/datasets/V24/data_pool/rwanda_tree_shapes/Training_Data_manual_Trial29_V9_2008.shp\",\n",
    "    \"train_data_path_rw_2008\": \"data/datasets/V24/train/rwanda_2008\",\n",
    "    \"val_data_path_rw_2008\": \"data/datasets/V24/val/rwanda_2008\",\n",
    "    \"test_data_path_rw_2008\": \"data/datasets/V24/test/rwanda_2008\",\n",
    "\n",
    "    #Rwanda data 2019\n",
    "    \"shape_path_rw_2019\": \"data/datasets/V24/data_pool/rwanda_tree_shapes/Training_Data_manual_Trial29_V9_2020.shp\",\n",
    "    \"train_data_path_rw_2019\": \"data/datasets/V24/train/rwanda_2019\",\n",
    "    \"val_data_path_rw_2019\": \"data/datasets/V24/val/rwanda_2019\",\n",
    "    \"test_data_path_rw_2019\": \"data/datasets/V24/test/rwanda_2019\",\n",
    "\n",
    "\n",
    "\n",
    "    \"val_patch_size\": [256,256],# [x,y,bands]\n",
    "    \"val_overlap\": 200,\n",
    "    \n",
    "    \"padding\": False,#True\n",
    "\n",
    "   \n",
    "    #batch_size = 200\n",
    "    #batch_size = 50\n",
    "    \"batch_size\": 50, #50 #150 #75\n",
    "\n",
    "   \n",
    "    \"metric\": \"iou\",\n",
    "\n",
    "    \"n_channels\": 3,\n",
    "\n",
    "    \"nworkers\": 4,\n",
    "    \"pin_memory\": True,\n",
    "\n",
    "\n",
    "   \n",
    "}\n",
    "image_dir =\"data/out/validate/\"+ cfg[\"model_name\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ab15ff-f329-4613-ab04-53af775dfa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "val_transform = seg_transforms.Compose([\n",
    "    #seg_transforms.CLAHE_Norm(),\n",
    "    # seg_transforms.RandomHorizontalFlip(0.5),\n",
    "    # seg_transforms.RandomVerticalFlip(0.5),\n",
    "    #seg_transforms.UnmaskEdges([225,225])\n",
    "#         seg_transforms.Normalize(mean=[0.5492, 0.5190, 0.4393],\n",
    "#                                          std=[0.1381, 0.1320, 0.1349])\n",
    "])\n",
    "\n",
    "test_transform = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05191b7-4e6f-4b18-94f6-d14cc3819d1b",
   "metadata": {},
   "source": [
    "# 1.1 Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea7b58-0349-46ad-821a-5f9fa4256d80",
   "metadata": {},
   "source": [
    "#### Create Training and Test Dataset - SA high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c77230f-ff86-4939-90cd-e682ee637e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:05<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Val:  11245\n"
     ]
    }
   ],
   "source": [
    "val_dataset_sa_high = TrainDataset(dataset_path=None,data_file_path=cfg[\"val_data_path_sa_high\"],\n",
    "                   shape_path=cfg[\"shape_path_sa_high\"],\n",
    "                             overlap=cfg[\"val_overlap\"],patch_size=cfg[\"val_patch_size\"],padding=cfg[\"padding\"],transform=val_transform)\n",
    "\n",
    "print(\"Len Val: \",len(val_dataset_sa_high))\n",
    "#print(\"Len Test: \",len(test_dataset_sa))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d80f1-9b51-4a9b-84c3-aa88019020ef",
   "metadata": {},
   "source": [
    "#### Create Training and Test Dataset - SA low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01bc0040-f770-44a3-a14e-c94c628515d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:01<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Val:  708\n"
     ]
    }
   ],
   "source": [
    "val_dataset_sa_low = TrainDataset(dataset_path=None,data_file_path=cfg[\"val_data_path_sa_low\"],\n",
    "                   shape_path=cfg[\"shape_path_sa_low\"],\n",
    "                             overlap=cfg[\"val_overlap\"],patch_size=cfg[\"val_patch_size\"],padding=cfg[\"padding\"],transform=val_transform)\n",
    "\n",
    "\n",
    "print(\"Len Val: \",len(val_dataset_sa_low))\n",
    "#print(\"Len Test: \",len(test_dataset_sa))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de438184-bcc8-4c80-9246-f4f099e6bd4e",
   "metadata": {},
   "source": [
    "#### Create Training and Test Dataset - Rwanda 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0528187d-5f35-415a-a85a-76dcf8de6348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:16<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Val:  8686\n"
     ]
    }
   ],
   "source": [
    "val_dataset_rw_2008 = TrainDataset(dataset_path=None,data_file_path=cfg[\"val_data_path_rw_2008\"],\n",
    "                   shape_path=cfg[\"shape_path_rw_2008\"],\n",
    "                             overlap=cfg[\"val_overlap\"],patch_size=cfg[\"val_patch_size\"],padding=cfg[\"padding\"],transform=val_transform)\n",
    "\n",
    "print(\"Len Val: \",len(val_dataset_rw_2008))\n",
    "#print(\"Len Test: \",len(test_dataset_rw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe63c9f-56a2-49c5-83e1-377d30070152",
   "metadata": {},
   "source": [
    "#### Create Training and Test Dataset - Rwanda 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1391020-5a5c-4e64-bd83-1964d04fc620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:09<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Val:  5004\n"
     ]
    }
   ],
   "source": [
    "val_dataset_rw_2019 = TrainDataset(dataset_path=None,data_file_path=cfg[\"val_data_path_rw_2019\"],\n",
    "                   shape_path=cfg[\"shape_path_rw_2019\"],\n",
    "                             overlap=cfg[\"val_overlap\"],patch_size=cfg[\"val_patch_size\"],padding=cfg[\"padding\"],transform=val_transform)\n",
    "\n",
    "print(\"Len Val: \",len(val_dataset_rw_2019))\n",
    "#print(\"Len Test: \",len(test_dataset_rw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff2f9c1-9f81-48f5-91ea-d58c4c765ba1",
   "metadata": {},
   "source": [
    "# 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada6926b-d989-446a-952f-bc58be5fd6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = cfg[\"save_dir\"] + \"/\" + cfg[\"model_name\"] +  \".pth\"\n",
    "state_dict = torch.load(model_path,map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54fd4a0b-4538-40f4-ae35-9bbdc9619dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if cfg[\"data_parallel\"]:\n",
    "    # create new OrderedDict that does not contain `module.`\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    model_path = cfg[\"save_dir\"] + \"/\" + cfg[\"model_name\"] +  \"_new.pth\"\n",
    "    torch.save(new_state_dict,model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7da2b9-1025-4c6d-8ff4-a18aebd7371b",
   "metadata": {},
   "source": [
    "## 2.1 Advanced Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df1263a-a431-41d3-bb71-3a5636b26064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change here to adapt to your data\n",
    "# n_channels=3 for RGB images \n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "\n",
    "net = UNet(n_channels=3, n_classes=2, bilinear=False)\n",
    "#net= DataParallel(net)\n",
    "\n",
    "if cfg[\"data_parallel\"]:\n",
    "    net.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    net.load_state_dict(state_dict)\n",
    "#net.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n",
    "\n",
    "\n",
    "#net= DataParallel(net,device_ids=[0,1])\n",
    "net = net.to(device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9dee1-addf-44a5-b5b4-42e2e63d36e8",
   "metadata": {},
   "source": [
    "# 2.2 Model Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef557c4-d877-4872-a5e5-083232ea1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_dataset = torch.utils.data.ConcatDataset([val_dataset_rw_2008,val_dataset_rw_2019, val_dataset_sa_high,val_dataset_sa_low])\n",
    "#test_dataset = torch.utils.data.ConcatDataset([test_dataset_rw, test_dataset_sa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8c4879d-43b9-4050-a407-352b875f225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = torch.utils.data.ConcatDataset([val_dataset_rw_2008,val_dataset_rw_2019, val_dataset_sa_high,val_dataset_sa_low])\n",
    "\n",
    "if (len(val_dataset) % cfg[\"batch_size\"]) < cfg[\"nimgs\"]:\n",
    "    val_dl = DataLoader(val_dataset,batch_size=cfg[\"batch_size\"],num_workers=cfg[\"nworkers\"],\n",
    "                     shuffle=True,pin_memory=cfg[\"pin_memory\"],drop_last=True)\n",
    "else:\n",
    "    val_dl = DataLoader(val_dataset,batch_size=cfg[\"batch_size\"],num_workers=cfg[\"nworkers\"],\n",
    "                         shuffle=True,pin_memory=cfg[\"pin_memory\"],drop_last=False)\n",
    "# test_dl = DataLoader(test_dataset,batch_size=batch_size,num_workers=nworkers,\n",
    "#                      shuffle=False,pin_memory=pin_memory,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e10cf153-c176-4fe3-8f2d-ffe177532888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: acc     0.877653\n",
      "iou     0.369249\n",
      "dice    0.489295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "acc     0.877653\n",
       "iou     0.369249\n",
       "dice    0.489295\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(net,val_dl,image_dir,n_images=cfg[\"nimgs\"],device=device,mode=cfg[\"mode\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
